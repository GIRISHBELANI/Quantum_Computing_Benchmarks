{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b348a6-4cb2-4236-8765-3a1f26e176d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MaxCut Benchmark Program - Qiskit\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from qiskit import (Aer, ClassicalRegister,  # for computing expectation tables\n",
    "                    QuantumCircuit, QuantumRegister, execute, transpile)\n",
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "sys.path[1:1] = [ \"_common\", \"_common/qiskit\", \"maxcut/_common\" ]\n",
    "sys.path[1:1] = [ \"../../_common\", \"../../_common/qiskit\", \"../../maxcut/_common/\" ]\n",
    "import common\n",
    "import execute as ex\n",
    "import metrics as metrics\n",
    "\n",
    "# DEVNOTE: this logging feature should be moved to common level\n",
    "logger = logging.getLogger(__name__)\n",
    "fname, _, ext = os.path.basename(__file__).partition(\".\")\n",
    "log_to_file = False\n",
    "\n",
    "try:\n",
    "    if log_to_file:\n",
    "        logging.basicConfig(\n",
    "            # filename=f\"{fname}_{datetime.datetime.now().strftime('%Y_%m_%d_%S')}.log\",\n",
    "            filename=f\"{fname}.log\",\n",
    "            filemode='w',\n",
    "            encoding='utf-8',\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s %(name)s - %(levelname)s:%(message)s'\n",
    "        )\n",
    "    else:\n",
    "        logging.basicConfig(\n",
    "            level=logging.WARNING,\n",
    "            format='%(asctime)s %(name)s - %(levelname)s:%(message)s')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'Exception {e} occured while configuring logger: bypassing logger config to prevent data loss')\n",
    "    pass\n",
    "\n",
    "# Benchmark Name\n",
    "benchmark_name = \"MaxCut\"\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "maxcut_inputs = dict() #inputs to the run method\n",
    "verbose = False\n",
    "print_sample_circuit = True\n",
    "# Indicates whether to perform the (expensive) pre compute of expectations\n",
    "do_compute_expectation = True\n",
    "\n",
    "# saved circuits for display\n",
    "QC_ = None\n",
    "Uf_ = None\n",
    "\n",
    "# based on examples from https://qiskit.org/textbook/ch-applications/qaoa.html\n",
    "QAOA_Parameter  = namedtuple('QAOA_Parameter', ['beta', 'gamma'])\n",
    "\n",
    "# Qiskit uses the little-Endian convention. Hence, measured bit-strings need to be reversed while evaluating cut sizes\n",
    "reverseStep = -1\n",
    "\n",
    "#%% MaxCut circuit creation and fidelity analaysis functions\n",
    "def create_qaoa_circ(nqubits, edges, parameters):\n",
    "\n",
    "    qc = QuantumCircuit(nqubits)\n",
    "\n",
    "    # initial_state\n",
    "    for i in range(0, nqubits):\n",
    "        qc.h(i)\n",
    "\n",
    "    for par in parameters:\n",
    "        #print(f\"... gamma, beta = {par.gamma} {par.beta}\")\n",
    "        \n",
    "        # problem unitary\n",
    "        for i,j in edges:\n",
    "            qc.rzz(- par.gamma, i, j)\n",
    "\n",
    "        qc.barrier()\n",
    "        \n",
    "        # mixer unitary\n",
    "        for i in range(0, nqubits):\n",
    "            qc.rx(2 * par.beta, i)\n",
    "\n",
    "    return qc\n",
    "   \n",
    "\n",
    "def MaxCut (num_qubits, secret_int, edges, rounds, thetas_array, parameterized, measured = True):\n",
    "\n",
    "    if parameterized:\n",
    "        return MaxCut_param(num_qubits, secret_int, edges, rounds, thetas_array)\n",
    "\n",
    "    # if no thetas_array passed in, create defaults \n",
    "    if thetas_array is None:\n",
    "        thetas_array = 2*rounds*[1.0]\n",
    "    \n",
    "    #print(f\"... incoming thetas_array={thetas_array} rounds={rounds}\")\n",
    "       \n",
    "    # get number of qaoa rounds (p) from length of incoming array\n",
    "    p = len(thetas_array)//2 \n",
    "    \n",
    "    # if rounds passed in is less than p, truncate array\n",
    "    if rounds < p:\n",
    "        p = rounds\n",
    "        thetas_array = thetas_array[:2*rounds]\n",
    "    \n",
    "    # if more rounds requested than in thetas_array, give warning (can fill array later)\n",
    "    elif rounds > p:\n",
    "        rounds = p\n",
    "        print(f\"WARNING: rounds is greater than length of thetas_array/2; using rounds={rounds}\")\n",
    "    \n",
    "    logger.info(f'*** Constructing NON-parameterized circuit for {num_qubits = } {secret_int}')\n",
    "    \n",
    "    # create parameters in the form expected by the ansatz generator\n",
    "    # this is an array of betas followed by array of gammas, each of length = rounds\n",
    "    betas = thetas_array[:p]\n",
    "    gammas = thetas_array[p:]\n",
    "    parameters = [QAOA_Parameter(*t) for t in zip(betas,gammas)]\n",
    "           \n",
    "    # and create the circuit, without measurements\n",
    "    qc = create_qaoa_circ(num_qubits, edges, parameters)   \n",
    "\n",
    "    # pre-compute and save an array of expected measurements\n",
    "    if do_compute_expectation:\n",
    "        logger.info('Computing expectation')\n",
    "        compute_expectation(qc, num_qubits, secret_int)\n",
    "        \n",
    "    # add the measure here\n",
    "    if measured: qc.measure_all()\n",
    "        \n",
    "    # save small circuit example for display\n",
    "    global QC_\n",
    "    if QC_ == None or num_qubits <= 6:\n",
    "        if num_qubits < 9: QC_ = qc\n",
    "\n",
    "    # return a handle on the circuit\n",
    "    return qc, None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66aeb72-17d3-4e62-a168-36240ac8f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############### Circuit Definition - Parameterized version\n",
    "  \n",
    "# Create ansatz specific to this problem, defined by G = nodes, edges, and the given parameters\n",
    "# Do not include the measure operation, so we can pre-compute statevector\n",
    "def create_qaoa_circ_param(nqubits, edges, betas, gammas):\n",
    "\n",
    "    qc = QuantumCircuit(nqubits)\n",
    "\n",
    "    # initial_state\n",
    "    for i in range(0, nqubits):\n",
    "        qc.h(i)\n",
    "\n",
    "    for beta, gamma in zip(betas, gammas):\n",
    "        #print(f\"... gamma, beta = {gammas}, {betas}\")\n",
    "        \n",
    "        # problem unitary\n",
    "        for i,j in edges:\n",
    "            qc.rzz(- gamma, i, j)\n",
    "\n",
    "        qc.barrier()\n",
    "        \n",
    "        # mixer unitary\n",
    "        for i in range(0, nqubits):\n",
    "            qc.rx(2 * beta, i)\n",
    "\n",
    "    return qc\n",
    "  \n",
    "_qc = None\n",
    "beta_params = []\n",
    "gamma_params = []\n",
    "        \n",
    "# Create the benchmark program circuit\n",
    "# Accepts optional rounds and array of thetas (betas and gammas)\n",
    "def MaxCut_param (num_qubits, secret_int, edges, rounds, thetas_array):\n",
    "    # if no thetas_array passed in, create defaults \n",
    "    if thetas_array is None:\n",
    "        thetas_array = 2*rounds*[1.0]\n",
    "    \n",
    "    #print(f\"... incoming thetas_array={thetas_array} rounds={rounds}\")\n",
    "       \n",
    "    # get number of qaoa rounds (p) from length of incoming array\n",
    "    p = len(thetas_array)//2 \n",
    "    \n",
    "    # if rounds passed in is less than p, truncate array\n",
    "    if rounds < p:\n",
    "        p = rounds\n",
    "        thetas_array = thetas_array[:2*rounds]\n",
    "    \n",
    "    # if more rounds requested than in thetas_array, give warning (can fill array later)\n",
    "    elif rounds > p:\n",
    "        rounds = p\n",
    "        print(f\"WARNING: rounds is greater than length of thetas_array/2; using rounds={rounds}\")\n",
    "    \n",
    "    #print(f\"... actual thetas_array={thetas_array}\")\n",
    "    \n",
    "    # create parameters in the form expected by the ansatz generator\n",
    "    # this is an array of betas followed by array of gammas, each of length = rounds\n",
    "    global _qc\n",
    "    global betas\n",
    "    global gammas\n",
    "    \n",
    "    # create the circuit the first time, add measurements\n",
    "    if ex.do_transpile_for_execute:\n",
    "        logger.info(f'*** Constructing parameterized circuit for {num_qubits = } {secret_int}')\n",
    "        betas = ParameterVector(\"ùû´\", p)\n",
    "        gammas = ParameterVector(\"ùû¨\", p)\n",
    "    \n",
    "        _qc = create_qaoa_circ_param(num_qubits, edges, betas, gammas)\n",
    "        \n",
    "        # add the measure here, only after circuit is created\n",
    "        _qc.measure_all()\n",
    "    \n",
    "    params = {betas: thetas_array[:p], gammas: thetas_array[p:]}   \n",
    "    #logger.info(f\"Binding parameters {params = }\")\n",
    "    logger.info(f\"Create binding parameters for {thetas_array}\")\n",
    "    \n",
    "    qc = _qc\n",
    "    #print(qc)\n",
    "    \n",
    "    # pre-compute and save an array of expected measurements\n",
    "    if do_compute_expectation:\n",
    "        logger.info('Computing expectation')\n",
    "        compute_expectation(qc, num_qubits, secret_int, params=params)\n",
    "   \n",
    "    # save small circuit example for display\n",
    "    global QC_\n",
    "    if QC_ == None or num_qubits <= 6:\n",
    "        if num_qubits < 9: QC_ = qc\n",
    "\n",
    "    # return a handle on the circuit\n",
    "    return qc, params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c537db4-5c80-4560-b84e-c56574e41c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Expectation Tables\n",
    "\n",
    "# DEVNOTE: We are building these tables on-demand for now, but for larger circuits\n",
    "# this will need to be pre-computed ahead of time and stored in a data file to avoid run-time delays.\n",
    "\n",
    "# dictionary used to store pre-computed expectations, keyed by num_qubits and secret_string\n",
    "# these are created at the time the circuit is created, then deleted when results are processed\n",
    "expectations = {}\n",
    "\n",
    "# Compute array of expectation values in range 0.0 to 1.0\n",
    "# Use statevector_simulator to obtain exact expectation\n",
    "def compute_expectation(qc, num_qubits, secret_int, backend_id='statevector_simulator', params=None):\n",
    "    \n",
    "    #ts = time.time()\n",
    "    if params != None:\n",
    "        qc = qc.bind_parameters(params)\n",
    "    \n",
    "    #execute statevector simulation\n",
    "    sv_backend = Aer.get_backend(backend_id)\n",
    "    sv_result = execute(qc, sv_backend).result()\n",
    "\n",
    "    # get the probability distribution\n",
    "    counts = sv_result.get_counts()\n",
    "\n",
    "    #print(f\"... statevector expectation = {counts}\")\n",
    "    \n",
    "    # store in table until circuit execution is complete\n",
    "    id = f\"_{num_qubits}_{secret_int}\"\n",
    "    expectations[id] = counts\n",
    "\n",
    "    #print(f\"  ... time to execute statevector simulator: {time.time() - ts}\")\n",
    "    \n",
    "# Return expected measurement array scaled to number of shots executed\n",
    "def get_expectation(num_qubits, degree, num_shots):\n",
    "\n",
    "    # find expectation counts for the given circuit \n",
    "    id = f\"_{num_qubits}_{degree}\"\n",
    "    if id in expectations:\n",
    "        counts = expectations[id]\n",
    "        \n",
    "        # scale to number of shots\n",
    "        for k, v in counts.items():\n",
    "            counts[k] = round(v * num_shots)\n",
    "        \n",
    "        # delete from the dictionary\n",
    "        del expectations[id]\n",
    "        \n",
    "        return counts\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ed03a-ce87-45ee-8208-1df8c3fc8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Result Data Analysis\n",
    "\n",
    "expected_dist = {}\n",
    "\n",
    "# Compare the measurement results obtained with the expected measurements to determine fidelity\n",
    "def analyze_and_print_result (qc, result, num_qubits, secret_int, num_shots):\n",
    "    global expected_dist\n",
    "    \n",
    "    # obtain counts from the result object\n",
    "    counts = result.get_counts(qc)\n",
    "    \n",
    "    # retrieve pre-computed expectation values for the circuit that just completed\n",
    "    expected_dist = get_expectation(num_qubits, secret_int, num_shots)\n",
    "    \n",
    "    # if the expectation is not being calculated (only need if we want to compute fidelity)\n",
    "    # assume that the expectation is the same as measured counts, yielding fidelity = 1\n",
    "    if expected_dist == None:\n",
    "        expected_dist = counts\n",
    "    \n",
    "    if verbose: print(f\"For width {num_qubits} problem {secret_int}\\n  measured: {counts}\\n  expected: {expected_dist}\")\n",
    "\n",
    "    # use our polarization fidelity rescaling\n",
    "    fidelity = metrics.polarization_fidelity(counts, expected_dist)\n",
    "\n",
    "    if verbose: print(f\"For secret int {secret_int} fidelity: {fidelity}\")\n",
    "    \n",
    "    return counts, fidelity\n",
    "\n",
    "\n",
    "#%% Computation of various metrics, such as approximation ratio, etc.\n",
    "def compute_cutsizes(results, nodes, edges):\n",
    "    \"\"\"\n",
    "    Given a result object, extract the values of meaasured cuts and the corresponding \n",
    "    counts into ndarrays. Also compute and return the corresponding cut sizes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cuts : list of strings\n",
    "        each element is a bitstring denoting a cut\n",
    "    counts : ndarray of ints\n",
    "        measured counts corresponding to cuts\n",
    "    sizes : ndarray of ints\n",
    "        cut sizes (i.e. number of edges crossing the cut)\n",
    "    \"\"\"\n",
    "    cuts = list(results.get_counts().keys())\n",
    "    counts = list(results.get_counts().values())\n",
    "    sizes = [common.eval_cut(nodes, edges, cut, reverseStep) for cut in cuts]\n",
    "    return cuts, counts, sizes\n",
    "\n",
    "def get_size_dist(counts, sizes):\n",
    "    \"\"\" For given measurement outcomes, i.e. combinations of cuts, counts and sizes, return counts corresponding to each cut size.\n",
    "    \"\"\"\n",
    "    unique_sizes = list(set(sizes))\n",
    "    unique_counts = [0] * len(unique_sizes)\n",
    "    \n",
    "    for i, size in enumerate(unique_sizes):\n",
    "        corresp_counts = [counts[ind] for ind,s in enumerate(sizes) if s == size]\n",
    "        unique_counts[i] = sum(corresp_counts)\n",
    "    \n",
    "    # Make sure that the scores are in ascending order\n",
    "    s_and_c_list = [[a,b] for (a,b) in zip(unique_sizes, unique_counts)]\n",
    "    s_and_c_list = sorted(s_and_c_list, key = lambda x : x[0])\n",
    "    unique_sizes = [x[0] for x in s_and_c_list]\n",
    "    unique_counts = [x[1] for x in s_and_c_list]\n",
    "    cumul_counts = np.cumsum(unique_counts)\n",
    "    return unique_counts, unique_sizes, cumul_counts.tolist()\n",
    "\n",
    "\n",
    "# Compute the objective function on a given sample\n",
    "def compute_sample_mean(counts, sizes, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the mean of cut sizes (i.e. the weighted average of sizes weighted by counts)\n",
    "    This approximates the expectation value of the state at the end of the circuit\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : ndarray of ints\n",
    "        measured counts corresponding to cuts\n",
    "    sizes : ndarray of ints\n",
    "        cut sizes (i.e. number of edges crossing the cut)\n",
    "    **kwargs : optional arguments\n",
    "        will be ignored\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    # Convert counts and sizes to ndarrays, if they are lists\n",
    "    counts, sizes = np.array(counts), np.array(sizes)\n",
    "\n",
    "    return - np.sum(counts * sizes) / np.sum(counts)\n",
    "\n",
    "def compute_cvar(counts, sizes, alpha = 0.1, **kwargs):\n",
    "    \"\"\"\n",
    "    Obtains the Conditional Value at Risk or CVaR for samples measured at the end of the variational circuit.\n",
    "    Reference: Barkoutsos, P. K., Nannicini, G., Robert, A., Tavernelli, I. & Woerner, S. Improving Variational Quantum Optimization using CVaR. Quantum 4, 256 (2020).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : ndarray of ints\n",
    "        measured counts corresponding to cuts\n",
    "    sizes : ndarray of ints\n",
    "        cut sizes (i.e. number of edges crossing the cut)\n",
    "    alpha : float, optional\n",
    "        Confidence interval value for CVaR. The default is 0.1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        CVaR value\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert counts and sizes to ndarrays, if they are lists\n",
    "    counts, sizes = np.array(counts), np.array(sizes)\n",
    "    \n",
    "    # Sort the negative of the cut sizes in a non-decreasing order.\n",
    "    # Sort counts in the same order as sizes, so that i^th element of each correspond to each other\n",
    "    sort_inds = np.argsort(-sizes)\n",
    "    sizes = sizes[sort_inds]\n",
    "    counts = counts[sort_inds]\n",
    "\n",
    "    # Choose only the top num_avgd = ceil(alpha * num_shots) cuts. These will be averaged over.\n",
    "    num_avgd = math.ceil(alpha * np.sum(counts))\n",
    "\n",
    "    # Compute cvar\n",
    "    cvar_sum = 0\n",
    "    counts_so_far = 0\n",
    "    for c, s in zip(counts, sizes):\n",
    "        if counts_so_far + c >= num_avgd:\n",
    "            cts_to_consider = num_avgd - counts_so_far\n",
    "            cvar_sum += cts_to_consider * s\n",
    "            break\n",
    "        else:\n",
    "            counts_so_far += c\n",
    "            cvar_sum += c * s\n",
    "\n",
    "    return - cvar_sum / num_avgd\n",
    "\n",
    "def compute_gibbs(counts, sizes, eta = 0.5, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the Gibbs objective function for given measurements\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : ndarray of ints\n",
    "        measured counts corresponding to cuts\n",
    "    sizes : ndarray of ints\n",
    "        cut sizes (i.e. number of edges crossing the cut)\n",
    "    eta : float, optional\n",
    "        Inverse Temperature\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        - Gibbs objective function value / optimal value\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert counts and sizes to ndarrays, if they are lists\n",
    "    counts, sizes = np.array(counts), np.array(sizes)\n",
    "    ls = max(sizes)#largest size\n",
    "    shifted_sizes = sizes - ls\n",
    "    \n",
    "    # gibbs = - np.log( np.sum(counts * np.exp(eta * sizes)) / np.sum(counts))\n",
    "    gibbs = - eta * ls - np.log(np.sum (counts / np.sum(counts) * np.exp(eta * shifted_sizes)))\n",
    "    return gibbs\n",
    "\n",
    "\n",
    "def compute_best_cut_from_measured(counts, sizes, **kwargs):\n",
    "    \"\"\"From the measured cuts, return the size of the largest cut\n",
    "    \"\"\"\n",
    "    return - np.max(sizes)\n",
    "\n",
    "\n",
    "def compute_quartiles(counts, sizes):\n",
    "    \"\"\"\n",
    "    Compute and return the sizes of the cuts at the three quartile values (i.e. 0.25, 0.5 and 0.75)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : ndarray of ints\n",
    "        measured counts corresponding to cuts\n",
    "    sizes : ndarray of ints\n",
    "        cut sizes (i.e. number of edges crossing the cut)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    quantile_sizes : ndarray of of 3 floats\n",
    "        sizes of cuts corresponding to the three quartile values.\n",
    "    \"\"\"\n",
    "    # Convert counts and sizes to ndarrays, if they are lists\n",
    "    counts, sizes = np.array(counts), np.array(sizes)\n",
    "\n",
    "    # Sort sizes and counts in the sequence of non-decreasing values of sizes\n",
    "    sort_inds = np.argsort(sizes)\n",
    "    sizes = sizes[sort_inds]\n",
    "    counts = counts[sort_inds]\n",
    "    num_shots = np.sum(counts)\n",
    "\n",
    "    q_vals = [0.25, 0.5, 0.75]\n",
    "    ct_vals = [math.floor(q * num_shots) for q in q_vals]\n",
    "\n",
    "    cumsum_counts = np.cumsum(counts)\n",
    "    locs = np.searchsorted(cumsum_counts, ct_vals)\n",
    "    quantile_sizes = sizes[locs]\n",
    "    return quantile_sizes\n",
    "\n",
    "def uniform_cut_sampling(num_qubits, degree, num_shots, _instances=None):\n",
    "    \"\"\"\n",
    "    For a given problem, i.e. num_qubits and degree values, sample cuts uniformly\n",
    "    at random from all possible cuts, num_shots number of times. Return the corresponding\n",
    "    cuts, counts and cut sizes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, load the nodes and edges corresponding to the problem \n",
    "    instance_filename = os.path.join(os.path.dirname(__file__),\n",
    "                                     \"..\", \"_common\", common.INSTANCE_DIR, \n",
    "                                     f\"mc_{num_qubits:03d}_{degree:03d}_000.txt\")\n",
    "    nodes, edges = common.read_maxcut_instance(instance_filename, _instances)\n",
    "    \n",
    "    # Obtain num_shots number of uniform random samples between 0 and 2 ** num_qubits\n",
    "    unif_cuts = np.random.randint(2 ** num_qubits, size=num_shots).tolist()\n",
    "    unif_cuts_uniq = list(set(unif_cuts))\n",
    "\n",
    "    # Get counts corresponding to each sampled int/cut\n",
    "    unif_counts = [unif_cuts.count(cut) for cut in unif_cuts_uniq]\n",
    "    unif_cuts = list(set(unif_cuts))\n",
    "\n",
    "    def int_to_bs(numb):\n",
    "        # Function for converting from an integer to (bit)strings of length num_qubits\n",
    "        strr = format(numb, \"b\") #convert to binary\n",
    "        strr = '0' * (num_qubits - len(strr)) + strr\n",
    "        return strr\n",
    "\n",
    "    unif_cuts = [int_to_bs(i) for i in unif_cuts]\n",
    "    unif_sizes = [common.eval_cut(nodes, edges, cut, reverseStep) for cut in unif_cuts]\n",
    "\n",
    "    # Also get the corresponding distribution of cut sizes\n",
    "    unique_counts_unif, unique_sizes_unif, cumul_counts_unif = get_size_dist(unif_counts, unif_sizes)\n",
    "\n",
    "    return unif_cuts, unif_counts, unif_sizes, unique_counts_unif, unique_sizes_unif, cumul_counts_unif\n",
    "\n",
    "\n",
    "\n",
    "def get_random_angles(rounds, restarts):\n",
    "    \"\"\"Create max_circuit number of random initial conditions\n",
    "\n",
    "    Args:\n",
    "        rounds (int): number of rounds in QAOA\n",
    "        restarts (int): number of random initial conditions \n",
    "\n",
    "    Returns:\n",
    "        restarts (list of lists of floats): list of length restarts. Each list element is a list of angles\n",
    "    \"\"\"\n",
    "    # restarts = min(10, restarts)\n",
    "    # Create random angles\n",
    "    theta_min = [0] * 2 * rounds\n",
    "    # Upper limit for betas=pi; upper limit for gammas=2pi\n",
    "    theta_max = [np.pi] * rounds + [2 * np.pi] * rounds\n",
    "    thetas = np.random.uniform(\n",
    "        low=theta_min, high=theta_max, size=(restarts, 2 * rounds)\n",
    "    )\n",
    "    thetas = thetas.tolist()\n",
    "    return thetas\n",
    "        \n",
    "\n",
    "\n",
    "def get_restart_angles(thetas_array, rounds, restarts):\n",
    "    \"\"\"\n",
    "    Create random initial conditions for the restart loop.\n",
    "    thetas_array takes precedence over restarts.\n",
    "    If the user inputs valid thetas_array, restarts will be inferred accordingly.\n",
    "    If thetas_array is None and restarts is 1, return all 1's as initial angles.\n",
    "    If thetas_array is None and restarts >1, generate restarts number of random initial conditions\n",
    "    If only one set of random angles are desired, then the user needs to create them and send as thetas_array \n",
    "\n",
    "    Args:\n",
    "        thetas_array (list of lists of floats): list of initial angles.\n",
    "        restarts (int): number of random initial conditions\n",
    "        rounds (int): of QAOA\n",
    "\n",
    "    Returns:\n",
    "        thetas (list of lists. Shape = (max_circuits, 2 * rounds))\n",
    "        restarts : int\n",
    "    \"\"\"\n",
    "    assert type(restarts) == int and restarts > 0, \"max_circuits must be an integer greater than 0\"\n",
    "    default_angles = [[1] * 2 * rounds]\n",
    "    default_restarts = 1\n",
    "    if thetas_array is None:\n",
    "        if restarts == 1:\n",
    "            # if the angles are none, but restarts equals 1, use default of all 1's\n",
    "            return default_angles, default_restarts\n",
    "        else:\n",
    "            # restarts can only be greater than 1.\n",
    "            return get_random_angles(rounds, restarts), restarts\n",
    "        \n",
    "    if type(thetas_array) != list:\n",
    "        # thetas_array is not None, but is also not a list.\n",
    "        print(\"thetas_array is not a list. Using random angles.\")\n",
    "        return get_random_angles(rounds, restarts), restarts\n",
    "    \n",
    "    # At this point, thetas_array is a list. check if thetas_array is a list of lists\n",
    "    if not all([type(item) == list for item in thetas_array]):\n",
    "        # if every list element is not a list, return random angles\n",
    "        print(\"thetas_array is not a list of lists. Using random angles.\")\n",
    "        return get_random_angles(rounds, restarts), restarts\n",
    "        \n",
    "    if not all([len(item) == 2 * rounds for item in thetas_array]):\n",
    "        # If not all list elements are lists of the correct length...\n",
    "        print(\"Each element of thetas_array must be a list of length 2 * rounds. Using random angles.\")\n",
    "        return get_random_angles(rounds, restarts), restarts\n",
    "    \n",
    "    # At this point, thetas_array is a list of lists of length 2*rounds. All conditions are satisfied. Return inputted angles.\n",
    "    return thetas_array, len(thetas_array)\n",
    "    \n",
    "    \n",
    "#%% Storing final iteration data to json file, and to metrics.circuit_metrics_final_iter\n",
    "\n",
    "def save_runtime_data(result_dict): # This function will need changes, since circuit metrics dictionaries are now different\n",
    "    cm = result_dict.get('circuit_metrics')\n",
    "    detail = result_dict.get('circuit_metrics_detail', None)\n",
    "    detail_2 = result_dict.get('circuit_metrics_detail_2', None)\n",
    "    benchmark_inputs = result_dict.get('benchmark_inputs', None)\n",
    "    final_iter_metrics = result_dict.get('circuit_metrics_final_iter')\n",
    "    backend_id = result_dict.get('benchmark_inputs').get('backend_id')\n",
    "    \n",
    "    metrics.circuit_metrics_detail_2 = detail_2\n",
    "    \n",
    "    for width in detail_2:\n",
    "        # unique_id = restart_ind * 1000 + minimizer_iter_ind\n",
    "        \n",
    "        restart_ind_list = list(detail_2.get(width).keys())\n",
    "        for restart_ind in restart_ind_list:\n",
    "            degree = cm[width]['1']['degree']\n",
    "            opt = final_iter_metrics[width]['1']['optimal_value']\n",
    "            instance_filename = os.path.join(os.path.dirname(__file__),\n",
    "                \"..\", \"_common\", common.INSTANCE_DIR, f\"mc_{int(width):03d}_{int(degree):03d}_000.txt\")\n",
    "            metrics.circuit_metrics[width] = detail.get(width)\n",
    "            metrics.circuit_metrics['subtitle'] = cm.get('subtitle')\n",
    "            \n",
    "            finIterDict = final_iter_metrics[width][restart_ind]\n",
    "            if benchmark_inputs['save_final_counts']:\n",
    "                # if the final iteration cut counts were stored, retrieve them\n",
    "                iter_dist = {'cuts' : finIterDict['cuts'], 'counts' : finIterDict['counts'], 'sizes' : finIterDict['sizes']}\n",
    "            else:\n",
    "                # The value of iter_dist does not matter otherwise\n",
    "                iter_dist = None\n",
    "            # Retrieve the distribution of cut sizes for the final iteration for this width and degree\n",
    "            iter_size_dist = {'unique_sizes' : finIterDict['unique_sizes'], 'unique_counts' : finIterDict['unique_counts'], 'cumul_counts' : finIterDict['cumul_counts']}\n",
    "\n",
    "            \n",
    "            converged_thetas_list = finIterDict.get('converged_thetas_list')\n",
    "            parent_folder_save = os.path.join('__data', f'{metrics.get_backend_label(backend_id)}')\n",
    "            store_final_iter_to_metrics_json(\n",
    "                num_qubits=int(width),\n",
    "                degree = int(degree),\n",
    "                restart_ind=int(restart_ind),\n",
    "                num_shots=int(benchmark_inputs['num_shots']),\n",
    "                converged_thetas_list=converged_thetas_list,\n",
    "                opt=opt,\n",
    "                iter_size_dist=iter_size_dist,\n",
    "                iter_dist = iter_dist,\n",
    "                dict_of_inputs=benchmark_inputs,\n",
    "                parent_folder_save=parent_folder_save,\n",
    "                save_final_counts=False,\n",
    "                save_res_to_file=True,\n",
    "                _instances=None\n",
    "            )\n",
    "\n",
    "\n",
    "def store_final_iter_to_metrics_json(num_qubits,\n",
    "                                     degree,\n",
    "                                     restart_ind,\n",
    "                                     num_shots,\n",
    "                                     converged_thetas_list,\n",
    "                                     opt,\n",
    "                                     iter_size_dist,\n",
    "                                     iter_dist,\n",
    "                                     parent_folder_save,\n",
    "                                     dict_of_inputs,\n",
    "                                     save_final_counts,\n",
    "                                     save_res_to_file,\n",
    "                                     _instances=None):\n",
    "    \"\"\"\n",
    "    For a given graph (specified by num_qubits and degree),\n",
    "    1. For a given restart, store properties of the final minimizer iteration to metrics.circuit_metrics_final_iter, and\n",
    "    2. Store various properties for all minimizer iterations for each restart to a json file.\n",
    "    Parameters\n",
    "    ----------\n",
    "        num_qubits, degree, restarts, num_shots : ints\n",
    "        parent_folder_save : string (location where json file will be stored)\n",
    "        dict_of_inputs : dictionary of inputs that were given to run()\n",
    "        save_final_counts: bool. If true, save counts, cuts and sizes for last iteration to json file.\n",
    "        save_res_to_file: bool. If False, do not save data to json file.\n",
    "        iter_size_dist : dictionary containing distribution of cut sizes.  Keys are 'unique_sizes', 'unique_counts' and         'cumul_counts'\n",
    "        opt (int) : Max Cut value\n",
    "    \"\"\"\n",
    "    # In order to compare with uniform random sampling, get some samples\n",
    "    unif_cuts, unif_counts, unif_sizes, unique_counts_unif, unique_sizes_unif, cumul_counts_unif = uniform_cut_sampling(\n",
    "        num_qubits, degree, num_shots, _instances)\n",
    "    unif_dict = {'unique_counts_unif': unique_counts_unif,\n",
    "                 'unique_sizes_unif': unique_sizes_unif,\n",
    "                 'cumul_counts_unif': cumul_counts_unif}  # store only the distribution of cut sizes, and not the cuts themselves\n",
    "\n",
    "    # Store properties such as (cuts, counts, sizes) of the final iteration, the converged theta values, as well as the known optimal value for the current problem, in metrics.circuit_metrics_final_iter. Also store uniform cut sampling results\n",
    "    metrics.store_props_final_iter(num_qubits, restart_ind, 'optimal_value', opt)\n",
    "    metrics.store_props_final_iter(num_qubits, restart_ind, None, iter_size_dist)\n",
    "    metrics.store_props_final_iter(num_qubits, restart_ind, 'converged_thetas_list', converged_thetas_list)\n",
    "    metrics.store_props_final_iter(num_qubits, restart_ind, None, unif_dict)\n",
    "    # metrics.store_props_final_iter(num_qubits, restart_ind, None, iter_dist) # do not store iter_dist, since it takes a lot of memory for larger widths, instead, store just iter_size_dist\n",
    "\n",
    "\n",
    "    if save_res_to_file:\n",
    "        # Save data to a json file\n",
    "        dump_to_json(parent_folder_save, num_qubits,\n",
    "                     degree, restart_ind, iter_size_dist, iter_dist, dict_of_inputs, converged_thetas_list, opt, unif_dict,\n",
    "                     save_final_counts=save_final_counts)\n",
    "\n",
    "def dump_to_json(parent_folder_save, num_qubits, degree, restart_ind, iter_size_dist, iter_dist,\n",
    "                 dict_of_inputs, converged_thetas_list, opt, unif_dict, save_final_counts=False):\n",
    "    \"\"\"\n",
    "    For a given problem (specified by number of qubits and graph degree) and restart_index, \n",
    "    save the evolution of various properties in a json file.\n",
    "    Items stored in the json file: Data from all iterations (iterations), inputs to run program ('general properties'), converged theta values ('converged_thetas_list'), max cut size for the graph (optimal_value), distribution of cut sizes for random uniform sampling (unif_dict), and distribution of cut sizes for the final iteration (final_size_dist)\n",
    "    if save_final_counts is True, then also store the distribution of cuts \n",
    "    \"\"\"\n",
    "    if not os.path.exists(parent_folder_save): os.makedirs(parent_folder_save)\n",
    "    store_loc = os.path.join(parent_folder_save,'width_{}_restartInd_{}.json'.format(num_qubits, restart_ind))\n",
    "    \n",
    "    # Obtain dictionary with iterations data corresponding to given restart_ind \n",
    "    all_restart_ids = list(metrics.circuit_metrics[str(num_qubits)].keys())\n",
    "    ids_this_restart = [r_id for r_id in all_restart_ids if int(r_id) // 1000 == restart_ind]\n",
    "    iterations_dict_this_restart =  {r_id : metrics.circuit_metrics[str(num_qubits)][r_id] for r_id in ids_this_restart}\n",
    "    # Values to be stored in json file\n",
    "    dict_to_store = {'iterations' : iterations_dict_this_restart}\n",
    "    dict_to_store['general_properties'] = dict_of_inputs\n",
    "    dict_to_store['converged_thetas_list'] = converged_thetas_list\n",
    "    dict_to_store['optimal_value'] = opt\n",
    "    dict_to_store['unif_dict'] = unif_dict\n",
    "    dict_to_store['final_size_dist'] = iter_size_dist\n",
    "    # Also store the value of counts obtained for the final counts\n",
    "    if save_final_counts:\n",
    "        dict_to_store['final_counts'] = iter_dist\n",
    "                                        #iter_dist.get_counts()\n",
    "    # Now save the output\n",
    "    with open(store_loc, 'w') as outfile:\n",
    "        json.dump(dict_to_store, outfile)\n",
    "\n",
    "#%% Loading saved data (from json files)\n",
    "\n",
    "def load_data_and_plot(folder=None, backend_id=None, **kwargs):\n",
    "    \"\"\"\n",
    "    The highest level function for loading stored data from a previous run\n",
    "    and plotting optgaps and area metrics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : string\n",
    "        Directory where json files are saved.\n",
    "    \"\"\"\n",
    "    _gen_prop = load_all_metrics(folder, backend_id=backend_id)\n",
    "    if _gen_prop != None:\n",
    "        gen_prop = {**_gen_prop, **kwargs}\n",
    "        plot_results_from_data(**gen_prop)\n",
    "\n",
    "\n",
    "def load_all_metrics(folder=None, backend_id=None):\n",
    "    \"\"\"\n",
    "    Load all data that was saved in a folder.\n",
    "    The saved data will be in json files in this folder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : string\n",
    "        Directory where json files are saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gen_prop : dict\n",
    "        of inputs that were used in maxcut_benchmark.run method\n",
    "    \"\"\"\n",
    "    \n",
    "    # if folder not passed in, create its name using standard format\n",
    "    if folder is None:\n",
    "        folder = f\"__data/{metrics.get_backend_label(backend_id)}\"\n",
    "        \n",
    "    # Note: folder here should be the folder where only the width=... files are stored, and not a folder higher up in the directory\n",
    "    assert os.path.isdir(folder), f\"Specified folder ({folder}) does not exist.\"\n",
    "    \n",
    "    metrics.init_metrics()\n",
    "    \n",
    "    list_of_files = os.listdir(folder)\n",
    "    width_restart_file_tuples = [(*get_width_restart_tuple_from_filename(fileName), fileName)\n",
    "                                 for (ind, fileName) in enumerate(list_of_files) if fileName.startswith(\"width\")]  # list with elements that are tuples->(width,restartInd,filename)\n",
    "\n",
    "    width_restart_file_tuples = sorted(width_restart_file_tuples, key=lambda x:(x[0], x[1])) #sort first by width, and then by restartInd\n",
    "    distinct_widths = list(set(it[0] for it in width_restart_file_tuples)) \n",
    "    list_of_files = [\n",
    "        [tup[2] for tup in width_restart_file_tuples if tup[0] == width] for width in distinct_widths\n",
    "        ]\n",
    "    \n",
    "    # connot continue without at least one dataset\n",
    "    if len(list_of_files) < 1:\n",
    "        print(\"ERROR: No result files found\")\n",
    "        return None\n",
    "        \n",
    "    for width_files in list_of_files:\n",
    "        # For each width, first load all the restart files\n",
    "        for fileName in width_files:\n",
    "            gen_prop = load_from_width_restart_file(folder, fileName)\n",
    "        \n",
    "        # next, do processing for the width\n",
    "        method = gen_prop['method']\n",
    "        if method == 2:\n",
    "            num_qubits, _ = get_width_restart_tuple_from_filename(width_files[0])\n",
    "            metrics.process_circuit_metrics_2_level(num_qubits)\n",
    "            metrics.finalize_group(str(num_qubits))\n",
    "            \n",
    "    # override device name with the backend_id if supplied by caller\n",
    "    if backend_id != None:\n",
    "        metrics.set_plot_subtitle(f\"Device = {backend_id}\")\n",
    "            \n",
    "    return gen_prop\n",
    "\n",
    "\n",
    "def load_from_width_restart_file(folder, fileName):\n",
    "    \"\"\"\n",
    "    Given a folder name and a file in it, load all the stored data and store the values in metrics.circuit_metrics.\n",
    "    Also return the converged values of thetas, the final counts and general properties.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : string\n",
    "        folder where the json file is located\n",
    "    fileName : string\n",
    "        name of the json file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gen_prop : dict\n",
    "        of inputs that were used in maxcut_benchmark.run method\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract num_qubits and s from file name\n",
    "    num_qubits, restart_ind = get_width_restart_tuple_from_filename(fileName)\n",
    "    print(f\"Loading from {fileName}, corresponding to {num_qubits} qubits and restart index {restart_ind}\")\n",
    "    with open(os.path.join(folder, fileName), 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        gen_prop = data['general_properties']\n",
    "        converged_thetas_list = data['converged_thetas_list']\n",
    "        unif_dict = data['unif_dict']\n",
    "        opt = data['optimal_value']\n",
    "        if gen_prop['save_final_counts']:\n",
    "            # Distribution of measured cuts\n",
    "            final_counts = data['final_counts']\n",
    "        final_size_dist = data['final_size_dist']\n",
    "        \n",
    "        backend_id = gen_prop.get('backend_id')\n",
    "        metrics.set_plot_subtitle(f\"Device = {backend_id}\")\n",
    "        \n",
    "        # Update circuit metrics\n",
    "        for circuit_id in data['iterations']:\n",
    "            # circuit_id = restart_ind * 1000 + minimizer_loop_ind\n",
    "            for metric, value in data['iterations'][circuit_id].items():\n",
    "                metrics.store_metric(num_qubits, circuit_id, metric, value)\n",
    "                \n",
    "        method = gen_prop['method']\n",
    "        if method == 2:\n",
    "            metrics.store_props_final_iter(num_qubits, restart_ind, 'optimal_value', opt)\n",
    "            metrics.store_props_final_iter(num_qubits, restart_ind, None, final_size_dist)\n",
    "            metrics.store_props_final_iter(num_qubits, restart_ind, 'converged_thetas_list', converged_thetas_list)\n",
    "            metrics.store_props_final_iter(num_qubits, restart_ind, None, unif_dict)\n",
    "            if gen_prop['save_final_counts']:\n",
    "                metrics.store_props_final_iter(num_qubits, restart_ind, None, final_counts)\n",
    "\n",
    "    return gen_prop\n",
    "    \n",
    "\n",
    "def get_width_restart_tuple_from_filename(fileName):\n",
    "    \"\"\"\n",
    "    Given a filename, extract the corresponding width and degree it corresponds to\n",
    "    For example the file \"width=4_degree=3.json\" corresponds to 4 qubits and degree 3\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fileName : TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_qubits : int\n",
    "        circuit width\n",
    "    degree : int\n",
    "        graph degree.\n",
    "\n",
    "    \"\"\"\n",
    "    pattern = 'width_([0-9]+)_restartInd_([0-9]+).json'\n",
    "    match = re.search(pattern, fileName)\n",
    "\n",
    "    # assert match is not None, f\"File {fileName} found inside folder. All files inside specified folder must be named in the format 'width_int_restartInd_int.json\"\n",
    "    num_qubits = int(match.groups()[0])\n",
    "    degree = int(match.groups()[1])\n",
    "    return (num_qubits,degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d5d2b-c97d-4641-a549-eb3c82549929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% Run method: Benchmarking loop\n",
    "\n",
    "MAX_QUBITS = 24\n",
    "iter_dist = {'cuts' : [], 'counts' : [], 'sizes' : []} # (list of measured bitstrings, list of corresponding counts, list of corresponding cut sizes)\n",
    "iter_size_dist = {'unique_sizes' : [], 'unique_counts' : [], 'cumul_counts' : []} # for the iteration being executed, stores the distribution for cut sizes\n",
    "saved_result = {  }\n",
    "instance_filename = None\n",
    "\n",
    "def run (min_qubits=3, max_qubits=16, skip_qubits=2,\n",
    "        max_circuits=1, num_shots=1000,\n",
    "        method=1, rounds=1, degree=3, alpha=0.1, thetas_array=None, parameterized= False, do_fidelities=True,\n",
    "        max_iter=30, score_metric='fidelity', x_metric='cumulative_exec_time', y_metric='num_qubits',\n",
    "        fixed_metrics={}, num_x_bins=15, y_size=None, x_size=None, use_fixed_angles=False,\n",
    "        objective_func_type = 'approx_ratio', plot_results = True,\n",
    "        save_res_to_file = False, save_final_counts = False, detailed_save_names = False, comfort=False,\n",
    "        backend_id='fake_guadalupe',      # A fake 16 qubits backend\n",
    "        provider_backend=None, eta=0.5,\n",
    "        hub=\"ibm-q\", group=\"open\", project=\"main\", exec_options=None,\n",
    "        context=None,\n",
    "        _instances=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    min_qubits : int, optional\n",
    "        The smallest circuit width for which benchmarking will be done The default is 3.\n",
    "    max_qubits : int, optional\n",
    "        The largest circuit width for which benchmarking will be done. The default is 6.\n",
    "    skip_qubits : int, optional\n",
    "        Skip at least this many qubits during run loop. The default is 2.\n",
    "    max_circuits : int, optional\n",
    "        Number of restarts. The default is None.\n",
    "    num_shots : int, optional\n",
    "        Number of times the circut will be measured, for each iteration. The default is 100.\n",
    "    method : int, optional\n",
    "        If 1, then do standard metrics, if 2, implement iterative algo metrics. The default is 1.\n",
    "    rounds : int, optional\n",
    "        number of QAOA rounds. The default is 1.\n",
    "    degree : int, optional\n",
    "        degree of graph. The default is 3.\n",
    "    thetas_array : list, optional\n",
    "        list or ndarray of beta and gamma values. The default is None.\n",
    "    use_fixed_angles : bool, optional\n",
    "        use betas and gammas obtained from a 'fixed angles' table, specific to degree and rounds\n",
    "    N : int, optional\n",
    "        For the max % counts metric, choose the highest N% counts. The default is 10.\n",
    "    alpha : float, optional\n",
    "        Value between 0 and 1. The default is 0.1.\n",
    "    parameterized : bool, optional\n",
    "        Whether to use parametrized circuits or not. The default is False.\n",
    "    do_fidelities : bool, optional\n",
    "        Compute circuit fidelity. The default is True.\n",
    "    max_iter : int, optional\n",
    "        Number of iterations for the minimizer routine. The default is 30.\n",
    "    score_metric : list or string, optional\n",
    "        Which metrics are to be plotted in area metrics plots. The default is 'fidelity'.\n",
    "    x_metric : list or string, optional\n",
    "        Horizontal axis for area plots. The default is 'cumulative_exec_time'.\n",
    "    y_metric : list or string, optional\n",
    "        Vertical axis for area plots. The default is 'num_qubits'.\n",
    "    fixed_metrics : TYPE, optional\n",
    "        DESCRIPTION. The default is {}.\n",
    "    num_x_bins : int, optional\n",
    "        DESCRIPTION. The default is 15.\n",
    "    y_size : TYPint, optional\n",
    "        DESCRIPTION. The default is None.\n",
    "    x_size : string, optional\n",
    "        DESCRIPTION. The default is None.\n",
    "    backend_id : string, optional\n",
    "        DESCRIPTION. The default is 'qasm_simulator'.\n",
    "    provider_backend : string, optional\n",
    "        DESCRIPTION. The default is None.\n",
    "    hub : string, optional\n",
    "        DESCRIPTION. The default is \"ibm-q\".\n",
    "    group : string, optional\n",
    "        DESCRIPTION. The default is \"open\".\n",
    "    project : string, optional\n",
    "        DESCRIPTION. The default is \"main\".\n",
    "    exec_options : string, optional\n",
    "        DESCRIPTION. The default is None.\n",
    "    objective_func_type : string, optional\n",
    "        Objective function to be used by the classical minimizer algorithm. The default is 'approx_ratio'.\n",
    "    plot_results : bool, optional\n",
    "        Plot results only if True. The default is True.\n",
    "    save_res_to_file : bool, optional\n",
    "        Save results to json files. The default is True.\n",
    "    save_final_counts : bool, optional\n",
    "        If True, also save the counts from the final iteration for each problem in the json files. The default is True.\n",
    "    detailed_save_names : bool, optional\n",
    "        If true, the data and plots will be saved with more detailed names. Default is False\n",
    "    confort : bool, optional    \n",
    "        If true, print comfort dots during execution\n",
    "    \"\"\"\n",
    "\n",
    "    # Store all the input parameters into a dictionary.\n",
    "    # This dictionary will later be stored in a json file\n",
    "    # It will also be used for sending parameters to the plotting function\n",
    "    dict_of_inputs = locals()\n",
    "    \n",
    "    # Get angles for restarts. Thetas = list of lists. Lengths are max_circuits and 2*rounds\n",
    "    thetas, max_circuits = get_restart_angles(thetas_array, rounds, max_circuits)\n",
    "    \n",
    "    # Update the dictionary of inputs\n",
    "    dict_of_inputs = {**dict_of_inputs, **{'thetas_array': thetas, 'max_circuits' : max_circuits}}\n",
    "    \n",
    "    # Delete some entries from the dictionary\n",
    "    for key in [\"hub\", \"group\", \"project\", \"provider_backend\", \"exec_options\"]:\n",
    "        dict_of_inputs.pop(key)\n",
    "    \n",
    "    global maxcut_inputs\n",
    "    maxcut_inputs = dict_of_inputs\n",
    "    \n",
    "    global QC_\n",
    "    global circuits_done\n",
    "    global minimizer_loop_index\n",
    "    global opt_ts\n",
    "    \n",
    "    print(f\"{benchmark_name} ({method}) Benchmark Program - Qiskit\")\n",
    "\n",
    "    QC_ = None\n",
    "    \n",
    "    # Create a folder where the results will be saved. Folder name=time of start of computation\n",
    "    # In particular, for every circuit width, the metrics will be stored the moment the results are obtained\n",
    "    # In addition to the metrics, the (beta,gamma) values obtained by the optimizer, as well as the counts\n",
    "    # measured for the final circuit will be stored.\n",
    "    # Use the following parent folder, for a more detailed \n",
    "    if detailed_save_names:\n",
    "        start_time_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        parent_folder_save = os.path.join('__results', f'{backend_id}', objective_func_type, f'run_start_{start_time_str}')\n",
    "    else:\n",
    "        parent_folder_save = os.path.join('__results', f'{backend_id}', objective_func_type)\n",
    "    \n",
    "    if save_res_to_file and not os.path.exists(parent_folder_save): os.makedirs(os.path.join(parent_folder_save))\n",
    "    \n",
    "    # validate parameters\n",
    "    max_qubits = max(4, max_qubits)\n",
    "    max_qubits = min(MAX_QUBITS, max_qubits)\n",
    "    min_qubits = min(max(4, min_qubits), max_qubits)\n",
    "    skip_qubits = max(2, skip_qubits)\n",
    "    \n",
    "    # create context identifier\n",
    "    if context is None: context = f\"{benchmark_name} ({method}) Benchmark\"\n",
    "    \n",
    "    degree = max(3, degree)\n",
    "    rounds = max(1, rounds)\n",
    "    \n",
    "    # don't compute exectation unless fidelity is is needed\n",
    "    global do_compute_expectation\n",
    "    do_compute_expectation = do_fidelities\n",
    "        \n",
    "    # given that this benchmark does every other width, set y_size default to 1.5\n",
    "    if y_size == None:\n",
    "        y_size = 1.5\n",
    "        \n",
    "    # Choose the objective function to minimize, based on values of the parameters\n",
    "    possible_approx_ratios = {'cvar_ratio', 'approx_ratio', 'gibbs_ratio', 'bestcut_ratio'}\n",
    "    non_objFunc_ratios = possible_approx_ratios - { objective_func_type }\n",
    "    function_mapper = {'cvar_ratio' : compute_cvar, \n",
    "                       'approx_ratio' : compute_sample_mean,\n",
    "                       'gibbs_ratio' : compute_gibbs,\n",
    "                       'bestcut_ratio' : compute_best_cut_from_measured}\n",
    "                       \n",
    "    # if using fixed angles, get thetas array from table\n",
    "    if use_fixed_angles:\n",
    "    \n",
    "        # Load the fixed angle tables from data file\n",
    "        fixed_angles = common.read_fixed_angles(\n",
    "            os.path.join(os.path.dirname(__file__), '..', '_common', 'angles_regular_graphs.json'),\n",
    "            _instances)\n",
    "            \n",
    "        thetas_array = common.get_fixed_angles_for(fixed_angles, degree, rounds)\n",
    "        if thetas_array == None:\n",
    "            print(f\"ERROR: no fixed angles for rounds = {rounds}\")\n",
    "            return\n",
    "           \n",
    "    ##########\n",
    "    \n",
    "    # Initialize metrics module\n",
    "    metrics.init_metrics()\n",
    "    \n",
    "    # Define custom result handler\n",
    "    def execution_handler (qc, result, num_qubits, s_int, num_shots):  \n",
    "     \n",
    "        # determine fidelity of result set\n",
    "        num_qubits = int(num_qubits)\n",
    "        counts, fidelity = analyze_and_print_result(qc, result, num_qubits, int(s_int), num_shots)\n",
    "        metrics.store_metric(num_qubits, s_int, 'fidelity', fidelity)\n",
    "\n",
    "    def execution_handler2 (qc, result, num_qubits, s_int, num_shots):\n",
    "        # Stores the results to the global saved_result variable\n",
    "        global saved_result\n",
    "        saved_result = result\n",
    "     \n",
    "    # Initialize execution module using the execution result handler above and specified backend_id\n",
    "    # for method=2 we need to set max_jobs_active to 1, so each circuit completes before continuing\n",
    "    if method == 2:\n",
    "        ex.max_jobs_active = 1\n",
    "        ex.init_execution(execution_handler2)\n",
    "    else:\n",
    "        ex.init_execution(execution_handler)\n",
    "    \n",
    "    # initialize the execution module with target information\n",
    "    ex.set_execution_target(backend_id, provider_backend=provider_backend,\n",
    "        hub=hub, group=group, project=project, \n",
    "        exec_options=exec_options,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    # for noiseless simulation, set noise model to be None\n",
    "    # ex.set_noise_model(None)\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    # Execute Benchmark Program N times for multiple circuit sizes\n",
    "    # Accumulate metrics asynchronously as circuits complete\n",
    "    # DEVNOTE: increment by 2 to match the collection of problems in 'instance' folder\n",
    "    for num_qubits in range(min_qubits, max_qubits + 1, 2):\n",
    "        \n",
    "        if method == 1:\n",
    "            print(f\"************\\nExecuting [{max_circuits}] circuits for num_qubits = {num_qubits}\")\n",
    "        else:\n",
    "            print(f\"************\\nExecuting [{max_circuits}] restarts for num_qubits = {num_qubits}\")\n",
    "        \n",
    "        # If degree is negative, \n",
    "        if degree < 0 :\n",
    "            degree = max(3, (num_qubits + degree))\n",
    "            \n",
    "        # Load the problem and its solution\n",
    "        global instance_filename\n",
    "        instance_filename = os.path.join(\n",
    "            os.path.dirname(__file__),\n",
    "            \"..\",\n",
    "            \"_common\",\n",
    "            common.INSTANCE_DIR,\n",
    "            f\"mc_{num_qubits:03d}_{degree:03d}_000.txt\",\n",
    "        )\n",
    "        nodes, edges = common.read_maxcut_instance(instance_filename, _instances)\n",
    "        opt, _ = common.read_maxcut_solution(\n",
    "            instance_filename[:-4] + \".sol\", _instances\n",
    "        )\n",
    "        \n",
    "        # if the file does not exist, we are done with this number of qubits\n",
    "        if nodes == None:\n",
    "            print(f\"  ... problem not found.\")\n",
    "            break\n",
    "        \n",
    "        for restart_ind in range(1, max_circuits + 1):\n",
    "            # restart index should start from 1\n",
    "            # Loop over restarts for a given graph\n",
    "            \n",
    "            # if not using fixed angles, get initial or random thetas from array saved earlier\n",
    "            # otherwise use random angles (if restarts > 1) or [1] * 2 * rounds\n",
    "            if not use_fixed_angles:\n",
    "                thetas_array = thetas[restart_ind - 1]\n",
    "                            \n",
    "            if method == 1:\n",
    "                # create the circuit for given qubit size and secret string, store time metric\n",
    "                ts = time.time()\n",
    "                \n",
    "                # if using fixed angles in method 1, need to access first element\n",
    "                # DEVNOTE: eliminate differences between method 1 and 2 and handling of thetas_array\n",
    "                thetas_array_0 = thetas_array\n",
    "                if use_fixed_angles:\n",
    "                    thetas_array_0 = thetas_array[0]\n",
    "                                       \n",
    "                qc, params = MaxCut(num_qubits, restart_ind, edges, rounds, thetas_array_0, parameterized)\n",
    "                metrics.store_metric(num_qubits, restart_ind, 'create_time', time.time()-ts)\n",
    "\n",
    "                # collapse the sub-circuit levels used in this benchmark (for qiskit)\n",
    "                qc2 = qc.decompose()\n",
    "\n",
    "                # submit circuit for execution on target (simulator, cloud simulator, or hardware)\n",
    "                ex.submit_circuit(qc2, num_qubits, restart_ind, shots=num_shots, params=params)\n",
    "\n",
    "            if method == 2:\n",
    "                # a unique circuit index used inside the inner minimizer loop as identifier\n",
    "                minimizer_loop_index = 0 # Value of 0 corresponds to the 0th iteration of the minimizer\n",
    "                start_iters_t = time.time()\n",
    "\n",
    "                # Always start by enabling transpile ...\n",
    "                ex.set_tranpilation_flags(do_transpile_metrics=True, do_transpile_for_execute=True)\n",
    "                    \n",
    "                logger.info(f'===============  Begin method 2 loop, enabling transpile')\n",
    "                \n",
    "                def expectation(thetas_array):\n",
    "                    \n",
    "                    # Every circuit needs a unique id; add unique_circuit_index instead of s_int\n",
    "                    global minimizer_loop_index\n",
    "                    unique_id = restart_ind * 1000 + minimizer_loop_index\n",
    "                    # store thetas_array\n",
    "                    metrics.store_metric(num_qubits, unique_id, 'thetas_array', thetas_array.tolist())\n",
    "                    \n",
    "                    #************************************************\n",
    "                    #*** Circuit Creation and Decomposition start ***\n",
    "                    # create the circuit for given qubit size, secret string and params, store time metric\n",
    "                    ts = time.time()\n",
    "                    qc, params = MaxCut(num_qubits, unique_id, edges, rounds, thetas_array, parameterized)\n",
    "                    metrics.store_metric(num_qubits, unique_id, 'create_time', time.time()-ts)\n",
    "                    \n",
    "                    # also store the 'rounds' and 'degree' for each execution\n",
    "                    # DEVNOTE: Currently, this is stored for each iteration. Reduce this redundancy\n",
    "                    metrics.store_metric(num_qubits, unique_id, 'rounds', rounds)\n",
    "                    metrics.store_metric(num_qubits, unique_id, 'degree', degree)\n",
    "                    \n",
    "                    # collapse the sub-circuit levels used in this benchmark (for qiskit)\n",
    "                    qc2 = qc.decompose()\n",
    "                    \n",
    "                    # Circuit Creation and Decomposition end\n",
    "                    #************************************************\n",
    "                    \n",
    "                    #************************************************\n",
    "                    #*** Quantum Part: Execution of Circuits ***\n",
    "                    # submit circuit for execution on target with the current parameters\n",
    "                    ex.submit_circuit(qc2, num_qubits, unique_id, shots=num_shots, params=params)\n",
    "                    \n",
    "                    # Must wait for circuit to complete\n",
    "                    #ex.throttle_execution(metrics.finalize_group)\n",
    "                    ex.finalize_execution(None, report_end=False)    # don't finalize group until all circuits done\n",
    "                    \n",
    "                    # after first execution and thereafter, no need for transpilation if parameterized\n",
    "                    if parameterized:\n",
    "                        ex.set_tranpilation_flags(do_transpile_metrics=False, do_transpile_for_execute=False)\n",
    "                        logger.info(f'**** First execution complete, disabling transpile')\n",
    "                    #************************************************\n",
    "                    \n",
    "                    global saved_result\n",
    "                    # Fidelity Calculation and Storage\n",
    "                    _, fidelity = analyze_and_print_result(qc, saved_result, num_qubits, unique_id, num_shots) \n",
    "                    metrics.store_metric(num_qubits, unique_id, 'fidelity', fidelity)\n",
    "                    \n",
    "                    #************************************************\n",
    "                    #*** Classical Processing of Results - essential to optimizer ***\n",
    "                    global opt_ts\n",
    "                    dict_of_vals = dict()\n",
    "                    # Start counting classical optimizer time here again\n",
    "                    tc1 = time.time()\n",
    "                    cuts, counts, sizes = compute_cutsizes(saved_result, nodes, edges)\n",
    "                    # Compute the value corresponding to the objective function first\n",
    "                    dict_of_vals[objective_func_type] = function_mapper[objective_func_type](counts, sizes, alpha = alpha)\n",
    "                    # Store the optimizer time as current time- tc1 + ts - opt_ts, since the time between tc1 and ts is not time used by the classical optimizer.\n",
    "                    metrics.store_metric(num_qubits, unique_id, 'opt_exec_time', time.time() - tc1 + ts - opt_ts)\n",
    "                    # Note: the first time it is stored it is just the initialization time for optimizer\n",
    "                    #************************************************\n",
    "                    \n",
    "                    #************************************************\n",
    "                    #*** Classical Processing of Results - not essential for optimizer. Used for tracking metrics ***\n",
    "                    # Compute the distribution of cut sizes; store them under metrics\n",
    "                    unique_counts, unique_sizes, cumul_counts = get_size_dist(counts, sizes)\n",
    "                    global iter_size_dist\n",
    "                    iter_size_dist = {'unique_sizes' : unique_sizes, 'unique_counts' : unique_counts, 'cumul_counts' : cumul_counts}\n",
    "                    metrics.store_metric(num_qubits, unique_id, None, iter_size_dist)\n",
    "\n",
    "                    # Compute and the other metrics (eg. cvar, gibbs and max N % if the obj function was set to approx ratio)\n",
    "                    for s in non_objFunc_ratios:\n",
    "                        dict_of_vals[s] = function_mapper[s](counts, sizes, alpha = alpha)\n",
    "                    # Store the ratios\n",
    "                    dict_of_ratios = { key : -1 * val / opt for (key, val) in dict_of_vals.items()}\n",
    "                    dict_of_ratios['gibbs_ratio'] = dict_of_ratios['gibbs_ratio'] / eta \n",
    "                    metrics.store_metric(num_qubits, unique_id, None, dict_of_ratios)\n",
    "                    # Get the best measurement and store it\n",
    "                    best = - compute_best_cut_from_measured(counts, sizes)\n",
    "                    metrics.store_metric(num_qubits, unique_id, 'bestcut_ratio', best / opt)\n",
    "                    # Also compute and store the weights of cuts at three quantile values\n",
    "                    quantile_sizes = compute_quartiles(counts, sizes)\n",
    "                    # Store quantile_optgaps as a list (allows storing in json files)\n",
    "                    metrics.store_metric(num_qubits, unique_id, 'quantile_optgaps', (1 - quantile_sizes / opt).tolist()) \n",
    "                    \n",
    "                    # Also store the cuts, counts and sizes in a global variable, to allow access elsewhere\n",
    "                    global iter_dist\n",
    "                    iter_dist = {'cuts' : cuts, 'counts' : counts, 'sizes' : sizes}\n",
    "                    minimizer_loop_index += 1\n",
    "                    #************************************************\n",
    "                    \n",
    "                    if comfort:\n",
    "                        if minimizer_loop_index == 1: print(\"\")\n",
    "                        print(\".\", end =\"\")\n",
    "\n",
    "                    # reset timer for optimizer execution after each iteration of quantum program completes\n",
    "                    opt_ts = time.time()\n",
    "                    \n",
    "                    return dict_of_vals[objective_func_type]\n",
    "                \n",
    "                # after first execution and thereafter, no need for transpilation if parameterized\n",
    "                # DEVNOTE: this appears to NOT be needed, as we can turn these off after \n",
    "                def callback(xk):\n",
    "                    if parameterized:\n",
    "                        ex.set_tranpilation_flags(do_transpile_metrics=False, do_transpile_for_execute=False)\n",
    "\n",
    "                opt_ts = time.time()\n",
    "                # perform the complete algorithm; minimizer invokes 'expectation' function iteratively\n",
    "                ##res = minimize(expectation, thetas_array, method='COBYLA', options = { 'maxiter': max_iter}, callback=callback)\n",
    "\n",
    "                res = minimize(expectation, thetas_array, method='COBYLA', options = { 'maxiter': max_iter})\n",
    "                # To-do: Set bounds for the minimizer\n",
    "                \n",
    "                unique_id = restart_ind * 1000 + 0\n",
    "                metrics.store_metric(num_qubits, unique_id, 'opt_exec_time', time.time()-opt_ts)\n",
    "                \n",
    "                if comfort:\n",
    "                    print(\"\")\n",
    "\n",
    "                # Save final iteration data to metrics.circuit_metrics_final_iter\n",
    "                # This data includes final counts, cuts, etc.\n",
    "                store_final_iter_to_metrics_json(num_qubits=num_qubits, \n",
    "                                                 degree=degree, \n",
    "                                                 restart_ind=restart_ind,\n",
    "                                                 num_shots=num_shots, \n",
    "                                                 converged_thetas_list=res.x.tolist(),\n",
    "                                                 opt=opt,\n",
    "                                                 iter_size_dist=iter_size_dist, iter_dist=iter_dist, parent_folder_save=parent_folder_save,\n",
    "                                                 dict_of_inputs=dict_of_inputs, save_final_counts=save_final_counts,\n",
    "                                                 save_res_to_file=save_res_to_file, _instances=_instances)\n",
    "\n",
    "        # for method 2, need to aggregate the detail metrics appropriately for each group\n",
    "        # Note that this assumes that all iterations of the circuit have completed by this point\n",
    "        if method == 2:                  \n",
    "            metrics.process_circuit_metrics_2_level(num_qubits)\n",
    "            metrics.finalize_group(str(num_qubits))\n",
    "            \n",
    "    # Wait for some active circuits to complete; report metrics when groups complete\n",
    "    ex.throttle_execution(metrics.finalize_group)\n",
    "        \n",
    "    # Wait for all active circuits to complete; report metrics when groups complete\n",
    "    ex.finalize_execution(metrics.finalize_group)\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    global print_sample_circuit\n",
    "    if print_sample_circuit:\n",
    "        # print a sample circuit\n",
    "        print(\"Sample Circuit:\"); print(QC_ if QC_ != None else \"  ... too large!\")\n",
    "    #if method == 1: print(\"\\nQuantum Oracle 'Uf' =\"); print(Uf_ if Uf_ != None else \" ... too large!\")\n",
    "\n",
    "    # Plot metrics for all circuit sizes\n",
    "    if method == 1:\n",
    "        metrics.plot_metrics(f\"Benchmark Results - {benchmark_name} ({method}) - Qiskit\",\n",
    "                options=dict(shots=num_shots,rounds=rounds))\n",
    "    elif method == 2:\n",
    "        #metrics.print_all_circuit_metrics()\n",
    "        if plot_results:\n",
    "            plot_results_from_data(**dict_of_inputs)\n",
    "\n",
    "# ******************************\n",
    "\n",
    "def plot_results_from_data(num_shots=1000, rounds=1, degree=3, max_iter=30, max_circuits = 1,\n",
    "            objective_func_type='approx_ratio', method=2, use_fixed_angles=False,\n",
    "            score_metric='fidelity', x_metric='cumulative_exec_time', y_metric='num_qubits', fixed_metrics={},\n",
    "            num_x_bins=15, y_size=None, x_size=None, x_min=None, x_max=None,\n",
    "            offset_flag=False,      # default is False for QAOA\n",
    "            detailed_save_names=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot results\n",
    "    \"\"\"\n",
    "\n",
    "    if detailed_save_names:\n",
    "        # If detailed names are desired for saving plots, put date of creation, etc.\n",
    "        cur_time=datetime.datetime.now()\n",
    "        dt = cur_time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        short_obj_func_str = metrics.score_label_save_str[objective_func_type]\n",
    "        suffix = f'-s{num_shots}_r{rounds}_d{degree}_mi{max_iter}_of-{short_obj_func_str}_{dt}' #of=objective function\n",
    "    else:\n",
    "        short_obj_func_str = metrics.score_label_save_str[objective_func_type]\n",
    "        suffix = f'of-{short_obj_func_str}' #of=objective function\n",
    "        \n",
    "    obj_str = metrics.known_score_labels[objective_func_type]\n",
    "    options = {'shots' : num_shots, 'rounds' : rounds, 'degree' : degree, 'restarts' : max_circuits, 'fixed_angles' : use_fixed_angles, '\\nObjective Function' : obj_str}\n",
    "    suptitle = f\"Benchmark Results - MaxCut ({method}) - Qiskit\"\n",
    "    \n",
    "    metrics.plot_all_area_metrics(f\"Benchmark Results - MaxCut ({method}) - Qiskit\",\n",
    "                score_metric=score_metric, x_metric=x_metric, y_metric=y_metric,\n",
    "                fixed_metrics=fixed_metrics, num_x_bins=num_x_bins,\n",
    "                x_size=x_size, y_size=y_size, x_min=x_min, x_max=x_max,\n",
    "                offset_flag=offset_flag,\n",
    "                options=options, suffix=suffix)\n",
    "    \n",
    "    metrics.plot_metrics_optgaps(suptitle, options=options, suffix=suffix, objective_func_type = objective_func_type)\n",
    "    \n",
    "    # this plot is deemed less useful\n",
    "    #metrics.plot_ECDF(suptitle=suptitle, options=options, suffix=suffix)\n",
    "\n",
    "    all_widths = list(metrics.circuit_metrics_final_iter.keys())\n",
    "    all_widths = [int(ii) for ii in all_widths]\n",
    "    list_of_widths = [all_widths[-1]]\n",
    "    metrics.plot_cutsize_distribution(suptitle=suptitle,options=options, suffix=suffix, list_of_widths = list_of_widths)\n",
    "    \n",
    "    metrics.plot_angles_polar(suptitle = suptitle, options = options, suffix = suffix)\n",
    "\n",
    "# if main, execute method\n",
    "if __name__ == '__main__': run()\n",
    "\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
